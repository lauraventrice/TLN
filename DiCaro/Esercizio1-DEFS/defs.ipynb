{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise “Defs”\n",
    "\n",
    "- Calculate similarity, seen as lexical overlap, between definitions in the `definitions.csv` document. (intersection cardinality normalized to minimum length between the two, or variants)\n",
    "- Aggregation on the two dimensions (concreteness/specificity), and results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully ✓\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import csv \n",
    "import json\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter \n",
    "import os \n",
    "\n",
    "print(\"Libraries imported successfully ✓\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read document definitions and create a data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "defs_path = f'resource/definitions.csv'\n",
    "defs_path_json = f'resource/definitions.json'\n",
    "slang_path = f'resource/slang.txt'\n",
    "\n",
    "if not os.path.exists(defs_path_json):\n",
    "    with open(defs_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        definitions = []\n",
    "        for row in reader:\n",
    "            definitions.append(row)\n",
    "\n",
    "    with open(defs_path_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(definitions, f, indent=4)\n",
    "\n",
    "\n",
    "with open(defs_path_json, 'r', encoding='utf-8') as f: \n",
    "    definitions = json.load(f)\n",
    "\n",
    "\n",
    "with open(slang_path, 'r', encoding='utf-8') as f:\n",
    "    slang = f.read().splitlines()\n",
    "    slangs = []\n",
    "    for pair in slang: \n",
    "        list_pair = pair.split(\"=\")\n",
    "        slangs.append((list_pair[0].lower(), list_pair[1].lower()))\n",
    "\n",
    "def expand_slangs(tokens: list, slangs: list):\n",
    "    for i, token in enumerate(tokens):\n",
    "        for slang in slangs:\n",
    "            if token == slang[0]:\n",
    "                tokens[i] = slang[1]\n",
    "    return tokens\n",
    "\n",
    "def expand_abbr(tokens: list): \n",
    "    for i, token in enumerate(tokens): \n",
    "        if token == \"e.g.\" or token == \"eg\":\n",
    "            tokens[i] = \"for example\"\n",
    "        elif token == \"i.e.\" or token == \"ie\":\n",
    "            tokens[i] = \"that is\"\n",
    "        elif token == \"e.i.\" or token == \"ei\":\n",
    "            tokens[i] = \"for example that is\"\n",
    "    return tokens\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  pre processing - stopwords removal, lemmatization, slang expansion, abbreviation expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "tokens_concepts = {}\n",
    "\n",
    "for concept in definitions: \n",
    "    keys = list(concept.keys())\n",
    "    keys.remove('Concept')\n",
    "    tokens = set()\n",
    "    for key in keys: # for all possible definition for the concept  \n",
    "        definition = concept[key].lower() \n",
    "        if definition != '':\n",
    "            def_tok = nltk.word_tokenize(definition)\n",
    "\n",
    "            def_tok = expand_slangs(def_tok, slangs) \n",
    "            def_tok = expand_abbr(def_tok) \n",
    "\n",
    "            def_tok = [token.lower() for token in def_tok if token not in stopwords and token.isalpha()]\n",
    "            lemmatizer = WordNetLemmatizer() \n",
    "            def_lem = [lemmatizer.lemmatize(token) for token in def_tok] \n",
    "            tokens.update(def_lem) \n",
    "            concept[key] = def_lem  \n",
    "        else: \n",
    "            del concept[key] \n",
    "    \n",
    "    tokens_concepts[concept['Concept']] = list(tokens) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creation of a phrase embedding (one-hot) for each definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_concepts = []\n",
    "\n",
    "for concept in definitions:\n",
    "    keys = list(concept.keys())\n",
    "    keys.remove('Concept')\n",
    "    embedding_concept = []\n",
    "    for key in keys:\n",
    "        definition = concept[key]\n",
    "        embedding = []\n",
    "        for token in tokens_concepts[concept['Concept']]:\n",
    "            if token in definition:\n",
    "                embedding.append(1)\n",
    "            else:\n",
    "                embedding.append(0)\n",
    "        embedding_concept.append(embedding)\n",
    "    \n",
    "    embeddings_concepts.append(embedding_concept)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Similarity between definitions using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(u, v):\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\n",
    "        return np.dot(u, v) / (norm(u) * norm(v))\n",
    "\n",
    "similarities = []\n",
    "for embedding_concept in embeddings_concepts: \n",
    "    sim_matrix_conc = []\n",
    "    for embedding in embedding_concept:\n",
    "        similarity_row = []\n",
    "        for embedding2 in embedding_concept:\n",
    "            cosine_similarity = cosine_sim(embedding, embedding2)\n",
    "            similarity_row.append(cosine_similarity)\n",
    "        sim_matrix_conc.append(similarity_row)\n",
    "\n",
    "    similarities.append(sim_matrix_conc)\n",
    "\n",
    "mean_concepts = []\n",
    "\n",
    "for similarity_conc in similarities:\n",
    "    mean_concept = []\n",
    "    for similarity in similarity_conc:\n",
    "        mean_def = np.mean(similarity)\n",
    "        mean_concept.append(mean_def)\n",
    "    \n",
    "    mean_conc = np.mean(mean_concept)\n",
    "    mean_concepts.append(mean_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity for each concept: \n",
      "\t\t --------------------------\n",
      "\t\t |   14.515   |   44.085  |\n",
      "\t\t |   13.418   |   37.106  |\n",
      "\t\t --------------------------\n"
     ]
    }
   ],
   "source": [
    "sim_perc = [sim*100 for sim in mean_concepts]\n",
    "print(\"\\nSimilarity for each concept: \")\n",
    "print(\"\\t\\t --------------------------\")\n",
    "print(\"\\t\\t |  \", round(sim_perc[0], 3), \"  |  \", round(sim_perc[1], 3), \" |\")\n",
    "print(\"\\t\\t |  \", round(sim_perc[2], 3), \"  |  \", round(sim_perc[3], 3), \" |\")\n",
    "print(\"\\t\\t --------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Statistics about concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 words per concept: \n",
      "Emotion\n",
      "[('feeling', 12), ('human', 8), ('feel', 8), ('something', 7), ('state', 4)]\n",
      "Person\n",
      "[('human', 29), ('person', 6), ('living', 4), ('individual', 3), ('certain', 3)]\n",
      "Revenge\n",
      "[('someone', 14), ('anger', 8), ('feeling', 7), ('action', 6), ('emotion', 6)]\n",
      "Brick\n",
      "[('used', 24), ('object', 16), ('material', 16), ('construction', 16), ('build', 13)]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Mean length of definitions for concept:\n",
      "Emotion :  4.1\n",
      "Person :  3.48\n",
      "Revenge :  5.53\n",
      "Brick :  5.19\n",
      "\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_top_words(definitions: list, n_top: int): \n",
    "    concept_counter = Counter()\n",
    "    \n",
    "    for definition in definitions:\n",
    "        concept_counter.update(definition)\n",
    "    \n",
    "    most_frequent_words = [entry for entry in concept_counter.most_common(n_top)]\n",
    "    return most_frequent_words\n",
    "\n",
    "print(\"\\nTop 5 words per concept: \")\n",
    "for concept in definitions: \n",
    "    keys = list(concept.keys())\n",
    "    print(concept['Concept'])\n",
    "    keys.remove('Concept')\n",
    "    top_words = get_top_words(concept.values(), 5)\n",
    "    print(top_words) \n",
    "\n",
    "print(\"\\n-----------------------------\\n\")\n",
    "# mean length of definitions for concept\n",
    "print(\"Mean length of definitions for concept:\")\n",
    "for concept in definitions:\n",
    "    keys = list(concept.keys())\n",
    "    keys.remove('Concept')\n",
    "    length = []\n",
    "    for key in keys:\n",
    "        definition = concept[key]\n",
    "        length.append(len(definition))\n",
    "    mean_length = np.mean(length)\n",
    "    print(concept['Concept'], \": \", round(mean_length, 2))\n",
    "\n",
    "print(\"\\n-----------------------------\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Mean similarity values between the two dimensions of concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity for concept type dimension \n",
      "Concrete:  0.406\n",
      "Abstract:  0.14\n",
      "Generic:   0.293\n",
      "Specific:  0.253\n"
     ]
    }
   ],
   "source": [
    "concrete_concept_mean = np.mean([mean_concepts[1], mean_concepts[3]])\n",
    "abstract_concept_mean = np.mean([mean_concepts[0], mean_concepts[2]])\n",
    "generic_concept_mean = np.mean([mean_concepts[0], mean_concepts[1]])\n",
    "specific_concept_mean = np.mean([mean_concepts[2], mean_concepts[3]])\n",
    "\n",
    "print(\"Mean similarity for concept type dimension \")\n",
    "print(\"Concrete: \", round(concrete_concept_mean, 3))\n",
    "print(\"Abstract: \", round(abstract_concept_mean, 3))\n",
    "print(\"Generic:  \", round(generic_concept_mean, 3))\n",
    "print(\"Specific: \", round(specific_concept_mean, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17f6057f19fd601e680b310ee2ebe0fee3e78679207250b2f4d8f20eb0597a02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
