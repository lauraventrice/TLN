{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usare wordnet per tradurle e avere i synset \n",
    "# https://www.nltk.org/howto/wordnet.html\n",
    "\n",
    "# https://linguistics.stackexchange.com/questions/19015/italian-is-there-an-authoritative-word-frequency-list\n",
    "\n",
    "# https://martinweisser.org/corpora_site/word_lists.html\n",
    "\n",
    "import re\n",
    "import os.path\n",
    "import pandas as pd\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian words loaded ✔ ( 16312 )\n",
      "English words loaded ✔ ( 20280 )\n"
     ]
    }
   ],
   "source": [
    "# 1. Extraction of pairs of false-friends words (eng-ita)\n",
    "\n",
    "path_corpus_ita = f'resource/ita/current_version_morph-it/morph-it_048_utf-8.txt'\n",
    "\n",
    "path_corpus_eng = f'resource/eng/BNC_lemmafile5.txt'\n",
    "\n",
    "path_words_ita = f'resource/ita/words_ita.txt'\n",
    "path_words_eng = f'resource/eng/words_eng.txt'\n",
    "\n",
    "pos_it = ['ADJ', 'ADV', 'ASP', 'AUX', 'CAU', 'MOD', 'NOUN', 'VER']\n",
    "words_ita = []\n",
    "pos_eng = ['j', 'v', 'n','r']\n",
    "words_eng = []\n",
    "\n",
    "# 1.1 Extraction of words from corpora ITA - Morph-It! (15k words)\n",
    "\n",
    "if not os.path.exists(path_words_ita) and os.path.exists(path_corpus_ita):\n",
    "    with open(path_corpus_ita, 'r', encoding='utf-8') as morph_it_file:\n",
    "        reader = morph_it_file.readlines()\n",
    "        for row in reader:\n",
    "            text, lemma, pos = re.split('\\t+', row)\n",
    "            if lemma not in words_ita:\n",
    "                pos = pos.replace('\\n', '')\n",
    "                pos = pos.split(\":\")[0]\n",
    "                if pos in pos_it:\n",
    "                    words_ita.append(lemma)\n",
    "\n",
    "    with open(path_words_ita, 'w', encoding='utf-8') as words_ita_file:\n",
    "        for word in words_ita:\n",
    "            words_ita_file.write(word + '\\n')\n",
    "\n",
    "else: \n",
    "    with open(path_words_ita, 'r', encoding='utf-8') as words_ita_file:\n",
    "        reader = words_ita_file.readlines()\n",
    "        for row in reader:\n",
    "            words_ita.append(row.replace('\\n', ''))\n",
    "\n",
    "\n",
    "print(\"Italian words loaded ✔ (\", len(words_ita), \")\")\n",
    "\n",
    "\n",
    "# 1.2 Extraction of words from corpora ENG - The British National Corpus (BNC) extracted from WordSmith Tools\n",
    "\n",
    "# https://lexically.net/wordsmith/support/lemma_lists.html\n",
    "\n",
    "\n",
    "if not os.path.exists(path_words_eng) and os.path.exists(path_corpus_eng):\n",
    "    with open(path_corpus_eng, 'r', encoding='utf-8') as corpus_eng_file:\n",
    "        reader = corpus_eng_file.readlines()\n",
    "        for row in reader:\n",
    "            lemma = row.split(\" -> \")[0].lower()\n",
    "            if len(lemma) > 2 and lemma not in words_eng:\n",
    "                words_eng.append(lemma)\n",
    "\n",
    "    with open(path_words_eng, 'w', encoding='utf-8') as words_eng_file:\n",
    "        for word in words_eng:\n",
    "            words_eng_file.write(word + '\\n')\n",
    "\n",
    "else: \n",
    "    with open(path_words_eng, 'r', encoding='utf-8') as words_eng_file:\n",
    "        reader = words_eng_file.readlines()\n",
    "        for row in reader:\n",
    "            words_eng.append(row.replace('\\n', ''))\n",
    "\n",
    "print(\"English words loaded ✔ (\", len(words_eng), \")\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Extraction of pairs of false-friends words from words_eng and words_ita\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITA:  []\n",
      "EN:  [Synset('cask.n.01'), Synset('barrel.n.02')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "print(\"ITA: \", wn.synsets('casco', lang='ita'))\n",
    "\n",
    "print(\"EN: \", wn.synsets('cask'))\n",
    "\n",
    "# similarità tra lista di synsets?? palmer???\n",
    "\n",
    "# calcolo della similarità anche con altre metriche\n",
    "\n",
    "# BONUS: utilizzo fasttext!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Computation of similarity between pairs of synsets (eng-ita) using lesk algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17f6057f19fd601e680b310ee2ebe0fee3e78679207250b2f4d8f20eb0597a02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
