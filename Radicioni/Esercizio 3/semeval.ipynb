{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione SemEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.spatial.distance import cosine\n",
    "import os.path\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consegna 1 - Annotazione di coppie di parole \n",
    "\n",
    "L'annotazione consiste in un punteggio di semantic similarity di 50 coppie di termini.\n",
    "\n",
    "Il criterio da utilizzare è presente al link https://tinyurl.com/y6f8h2kd. \n",
    "\n",
    "In particolare: \n",
    "- 4: **Molto simili** -- Le parole sono sinonimi (e.g., midday-noon). \n",
    "- 3: **Simili** -- Le parole condividono gran parte delle idee di significato ma includono dettagli profondamente differenti (e.g., lion-zebra). \n",
    "- 2: **Leggermente simili** -- Le parole non hanno significato molto simile ma condividono un argomento/dominio/funzione/idee/concetti che sono correlati (e.g., house-window). \n",
    "- 1: **Differenti** -- Le parole descrivono chiaramente concetti differenti, ma condividono qualche piccolo dettaglio come una lontana relazione o un dominio di utilizzo simile in un documento (e.g., software-keyboard).\n",
    "- 0: **Totalmente differenti e scorrelati** -- Le due parole non significano la stessa cosa e riguardano argomenti differenti (e.g., pencil-frog)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Estrazione di 50 coppie a partire dal cognome \"Scarpinati\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scarpinati     :\tcoppie nell'intervallo 251-300\n"
     ]
    }
   ],
   "source": [
    "def get_range(surname: str) -> int:\n",
    "    nof_elements = 500\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % 10)\n",
    "    idx_intervallo = base_idx * 50+1\n",
    "    return idx_intervallo\n",
    " \n",
    "\n",
    "input_name = \"Scarpinati\"\n",
    "\n",
    "values = []\n",
    "sx = get_range(input_name)\n",
    "values.append(sx)\n",
    "dx = sx+50-1\n",
    "intervallo = \"\" + str(sx) + \"-\" + str(dx)\n",
    "print('{:15}:\\tcoppie nell\\'intervallo {}'.format(input_name, intervallo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['crittogramma', 'simbolo'], ['campus', 'università'], ['libertà', 'libertà'], ['tifone', 'ciclone'], ['manuale', 'guida turistica'], ['Ebola', 'virus Ebola'], ['principessa', 'biscotto'], ['treno', 'tram'], ['ecosistema', 'economia'], ['regina regnante', 'regina degli scacchi'], ['oro', 'zinco'], ['cursore', 'patatine fritte'], ['Rio delle Amazzoni', 'foresta'], ['tennis', 'statistica'], ['Bolzano', 'teorema'], ['altitudine', 'conversione'], ['barca', 'albero'], ['trono', 'spada'], ['cotone', 'maglione'], ['ciliegia', 'fragola'], ['Islam', 'Corano'], ['Neanderthal', 'sport'], ['nepotismo', 're'], ['personaggio', 'persona'], ['cisterna', 'vagone'], ['Mercurio', 'Giove'], ['bronchite', 'acetaminofene'], ['sangue', 'corpo'], ['islamofobia', 'ISIS'], ['uncinetto', 'uniforme'], ['Hadoop', 'touchscreen'], ['combustibile fossile', 'fossile'], ['mutante', 'sociobiologia'], ['sorella', 'fratello'], ['matita', 'storia'], ['eczema', 'dermatite'], ['imperatore', 'governatore'], ['corona', 'chiave'], ['algebra', 'operazione'], ['pistone', 'motore'], ['borsa di studio', 'retta'], ['libro', 'manoscritto'], ['lantana', 'bocca di leone'], ['buco nero', 'vuoto'], ['Impero Persiano', 'Ciro'], ['editoriale', 'notizia'], ['decorazione', 'busta'], ['squalo balena', 'aragosta'], ['mais', 'granturco'], ['disturbo bipolare', 'problema']]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "path_corpus = f\"utils/it.test.data.txt\"\n",
    "\n",
    "with open(path_corpus, 'r', encoding='utf8') as file:\n",
    "    reader = file.readlines()[sx:dx+1]\n",
    "    pairs = [line.strip().split(\"\\t\") for line in reader]\n",
    "    print(pairs)\n",
    "    print(len(pairs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Memorizzazione delle coppie estratte\n",
    "\n",
    "**ATTENZIONE!** NON ESEGUIRE PIU' QUESTA CELLA, IL FILE E' GIA' STATO CREATO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_extracted = f\"resources/it.test.data_extracted.tsv\"\n",
    "if not os.path.exists(path_extracted):\n",
    "    with open(path_extracted, 'w', newline='', encoding='utf8') as out_file:\n",
    "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "        tsv_writer.writerow([\"Term1\", \"Term2\"])\n",
    "        tsv_writer.writerows(pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Estrazione dei valori di similarità inseriti per ogni coppia e calcolo della media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 3.0, 4.0, 4.0, 2.0, 4.0, 0.0, 3.0, 2.0, 2.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 3.0, 3.0, 0.0, 0.0, 1.0, 0.0, 3.0, 3.0, 2.0]\n",
      "[2.5, 3.2, 4.0, 3.7, 3.0, 4.0, 0.2, 3.5, 2.3, 2.3, 3.2, 0.0, 2.5, 0.5, 0.0, 0.0, 1.2, 2.5, 3.2, 3.3, 3.0, 0.2, 2.2, 2.6, 1.2, 3.2, 1.5, 3.3, 1.2, 1.3, 0.1, 2.2, 0.1, 3.6, 0.3, 2.7, 3.3, 0.2, 3.0, 3.0, 1.2, 3.7, 3.4, 3.0, 1.3, 1.2, 1.0, 3.2, 3.7, 1.5]\n",
      "[2.75, 3.1, 4.0, 3.85, 2.5, 4.0, 0.1, 3.25, 2.15, 2.15, 3.1, 0.0, 2.75, 0.25, 0.0, 0.0, 1.1, 2.75, 3.1, 3.15, 2.5, 0.1, 2.1, 2.3, 0.6, 3.1, 1.25, 2.65, 1.1, 1.15, 0.05, 1.1, 0.05, 3.3, 0.15, 2.35, 3.15, 0.1, 2.0, 2.0, 0.6, 3.35, 3.2, 1.5, 0.65, 1.1, 0.5, 3.1, 3.35, 1.75]\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "similarity_livio = []\n",
    "similarity_laura = []\n",
    "mean_similarity = []\n",
    "\n",
    "path_annotated = f\"resources/it.test.data_annotated.tsv\"\n",
    "\n",
    "with open(path_annotated, 'r', encoding='utf8') as file:\n",
    "    tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
    "    header = next(tsv_file)\n",
    "    for line in tsv_file:\n",
    "        similarity_livio.append(float(line[2]))\n",
    "        similarity_laura.append(float(line[3]))\n",
    "\n",
    "mean_similarity = [(similarity_livio[i] + similarity_laura[i])/2 for i in range(50)]\n",
    "\n",
    "print(similarity_livio)\n",
    "print(similarity_laura)\n",
    "print(mean_similarity)\n",
    "\n",
    "print(len(similarity_laura))\n",
    "print(len(similarity_livio))\n",
    "print(len(mean_similarity))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Memorizzazione del documento con il valore medio di valutazione per ogni coppia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(path_annotated)\n",
    "\n",
    "with open(path_annotated, 'w', newline='', encoding='utf8') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow([\"Term1\", \"Term2\", \"Sim_Livio\", \"Sim_Laura\", \"Mean\"])\n",
    "    for pair, sim_livio, sim_laura, mean in zip(pairs, similarity_livio, similarity_laura, mean_similarity):\n",
    "        tsv_writer.writerow([pair[0], pair[1], sim_livio, sim_laura, mean])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Calcolare agreement fra gli annotatori (inter-rater agreement)\n",
    "\n",
    "Vengono utilizzati gli indici di correlazione di **Pearson** e **Spearman**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Inter Agreement with Pearson & Spearman:\n",
      "Pearson \n",
      "Coefficiente di correlazione: 0.8608464960885513\n",
      "p-value:  1.0915876501062841e-15\n",
      "\n",
      "\n",
      "Spearman \n",
      "Coefficiente di correlazione: 0.8717448999587988\n",
      "p-value:  1.7525719905898133e-16\n"
     ]
    }
   ],
   "source": [
    "print(\"##### Inter Agreement with Pearson & Spearman:\")\n",
    "pearson = pearsonr(similarity_livio, similarity_laura)\n",
    "spearman = spearmanr(similarity_livio, similarity_laura)\n",
    "print(\"Pearson \")\n",
    "print(\"Coefficiente di correlazione:\", pearson[0])\n",
    "print(\"p-value: \", pearson[1])\n",
    "print(\"\\n\\nSpearman \")\n",
    "print(\"Coefficiente di correlazione:\", spearman.correlation)\n",
    "print(\"p-value: \", spearman.pvalue)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6 Valutazione\n",
    "\n",
    "La valutazione dei punteggi annotati è in rapporto alla similarità ottenuta utilizzando i vettori NASARI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nasari_vectors() -> dict: \n",
    "    path_nasari = f\"utils/mini_NASARI.tsv\"\n",
    "    nasari_vectors = {}\n",
    "    with open(path_nasari, 'r', encoding='utf8') as file:\n",
    "        tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
    "        for line in tsv_file:\n",
    "            synset_id, synset_name = line[0].split(\"__\")\n",
    "            vector = [float(value) for value in line[1:]]\n",
    "            nasari_vectors[synset_id] = vector\n",
    "    return nasari_vectors\n",
    "\n",
    "def get_senses2synsets() -> dict: \n",
    "    path_senses2synsets = f\"utils/SemEval17_IT_senses2synsets.txt\"\n",
    "    senses2synsets = {}\n",
    "    with open(path_senses2synsets, 'r', encoding='utf8') as file:\n",
    "        reader = file.readlines()\n",
    "        i = 0\n",
    "        while i < len(reader):\n",
    "            if reader[i].startswith(\"#\"):\n",
    "                synset_name = reader[i][1:].strip()\n",
    "                synset_ids = []\n",
    "                i += 1\n",
    "                while i < len(reader) and not reader[i].startswith(\"#\"):\n",
    "                    synset_ids.append(reader[i].strip())\n",
    "                    i += 1\n",
    "                senses2synsets[synset_name] = synset_ids\n",
    "    return senses2synsets\n",
    "\n",
    "def get_synsets(word: str, nasari_vectors: dict, senses2synsets: dict) -> list:\n",
    "    synsets = []\n",
    "    if word in senses2synsets:\n",
    "        for synset_id in senses2synsets[word]:\n",
    "            if synset_id in nasari_vectors:\n",
    "                synsets.append(nasari_vectors[synset_id])\n",
    "    return synsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(v1: list, v2: list) -> float:\n",
    "    return 1 - cosine(v1, v2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crittogramma simbolo\n",
      "Similarity: 0.624\n",
      "campus università\n",
      "Similarity: 0.9408\n",
      "libertà libertà\n",
      "Similarity: 1\n",
      "tifone ciclone\n",
      "Similarity: 1\n",
      "manuale guida turistica\n",
      "Similarity: 0.8345\n",
      "Ebola virus Ebola\n",
      "Similarity: 0.993\n",
      "principessa biscotto\n",
      "Similarity: 0.3956\n",
      "treno tram\n",
      "Similarity: 0.8679\n",
      "ecosistema economia\n",
      "Similarity: 0.4969\n",
      "regina regnante regina degli scacchi\n",
      "No synsets found for at least one of the words\n",
      "oro zinco\n",
      "Similarity: 0.8507\n",
      "cursore patatine fritte\n",
      "Similarity: 0.3544\n",
      "Rio delle Amazzoni foresta\n",
      "Similarity: 0.6174\n",
      "tennis statistica\n",
      "Similarity: 0.6604\n",
      "Bolzano teorema\n",
      "Similarity: 0.5703\n",
      "altitudine conversione\n",
      "Similarity: 0.7004\n",
      "barca albero\n",
      "Similarity: 0.9279\n",
      "trono spada\n",
      "Similarity: 0.5891\n",
      "cotone maglione\n",
      "Similarity: 0.6254\n",
      "ciliegia fragola\n",
      "Similarity: 0.9073\n",
      "Islam Corano\n",
      "Similarity: 0.8843\n",
      "Neanderthal sport\n",
      "Similarity: 0.5034\n",
      "nepotismo re\n",
      "Similarity: 0.654\n",
      "personaggio persona\n",
      "Similarity: 1\n",
      "cisterna vagone\n",
      "Similarity: 0.5377\n",
      "Mercurio Giove\n",
      "Similarity: 1\n",
      "bronchite acetaminofene\n",
      "Similarity: 0.6769\n",
      "sangue corpo\n",
      "Similarity: 0.7127\n",
      "islamofobia ISIS\n",
      "Similarity: 0.7206\n",
      "uncinetto uniforme\n",
      "Similarity: 0.6059\n",
      "Hadoop touchscreen\n",
      "Similarity: 0.4627\n",
      "combustibile fossile fossile\n",
      "Similarity: 0.4849\n",
      "mutante sociobiologia\n",
      "Similarity: 0.695\n",
      "sorella fratello\n",
      "Similarity: 1\n",
      "matita storia\n",
      "Similarity: 0.6971\n",
      "eczema dermatite\n",
      "Similarity: 0.9712\n",
      "imperatore governatore\n",
      "Similarity: 0.9\n",
      "corona chiave\n",
      "Similarity: 0.8612\n",
      "algebra operazione\n",
      "Similarity: 0.8363\n",
      "pistone motore\n",
      "Similarity: 0.9808\n",
      "borsa di studio retta\n",
      "Similarity: 0.8931\n",
      "libro manoscritto\n",
      "Similarity: 0.829\n",
      "lantana bocca di leone\n",
      "Similarity: 0.8628\n",
      "buco nero vuoto\n",
      "Similarity: 0.9068\n",
      "Impero Persiano Ciro\n",
      "Similarity: 0.7807\n",
      "editoriale notizia\n",
      "Similarity: 0.9319\n",
      "decorazione busta\n",
      "Similarity: 0.5828\n",
      "squalo balena aragosta\n",
      "Similarity: 0.8194\n",
      "mais granturco\n",
      "Similarity: 1\n",
      "disturbo bipolare problema\n",
      "Similarity: 0.4845\n"
     ]
    }
   ],
   "source": [
    "nasari_vectors = get_nasari_vectors()\n",
    "senses2synsets = get_senses2synsets()\n",
    "\n",
    "similarities_nasari = []\n",
    "for word1, word2 in pairs: \n",
    "    print(word1, word2)\n",
    "    synsets1 = get_synsets(word1, nasari_vectors, senses2synsets)\n",
    "    synsets2 = get_synsets(word2, nasari_vectors, senses2synsets)\n",
    "    if len(synsets1) == 0 or len(synsets2) == 0:\n",
    "        print(\"No synsets found for at least one of the words\")\n",
    "        similarities_nasari.append(0)\n",
    "        continue\n",
    "    max_similarity = 0\n",
    "    for s1 in synsets1:\n",
    "        for s2 in synsets2:\n",
    "            similarity = get_cosine_similarity(s1, s2)\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "    similarities_nasari.append(round(max_similarity, 4))\n",
    "    print(\"Similarity:\", round(max_similarity, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7 Coefficienti di correlazione tra la media degli annotatori e i risultati di NASARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Intra Agreement with Pearson & Spearman:\n",
      "Pearson \n",
      "Coefficiente di correlazione: 0.4934492329834736\n",
      "p-value:  0.0002713485798726492\n",
      "\n",
      "\n",
      "Spearman \n",
      "Coefficiente di correlazione: 0.5742331662269193\n",
      "p-value:  1.2988340617971147e-05\n"
     ]
    }
   ],
   "source": [
    "def normalize_range(values: list, min: int, max: int) -> list: \n",
    "    values_norm = [min + (max - min) * val for val in values]\n",
    "    return values_norm\n",
    "\n",
    "mean_norm = normalize_range(mean_similarity, 0, 1)\n",
    "\n",
    "print(\"##### Intra Agreement with Pearson & Spearman:\")\n",
    "\n",
    "pearson = pearsonr(mean_norm, similarities_nasari)\n",
    "spearman = spearmanr(mean_norm, similarities_nasari)\n",
    "\n",
    "print(\"Pearson \")\n",
    "print(\"Coefficiente di correlazione:\", pearson[0])\n",
    "print(\"p-value: \", pearson[1])\n",
    "print(\"\\n\\nSpearman \")\n",
    "print(\"Coefficiente di correlazione:\", spearman.correlation)\n",
    "print(\"p-value: \", spearman.pvalue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17f6057f19fd601e680b310ee2ebe0fee3e78679207250b2f4d8f20eb0597a02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
